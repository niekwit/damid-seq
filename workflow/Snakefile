include: "scripts/general_functions.smk"
from scripts.resources import Resources
from snakemake.utils import min_version, validate
from snakemake.shell import shell

report: "report/workflow.rst"

# Workflow version
VERSION = "v0.6.0"

# Set minimum snakemake version
min_version("8.12.0")

# Wrapper version
wrapper_version = "v3.13.8"

logger.info(f"Workflow version: {VERSION}")
logger.info(f"Wrapper version: {wrapper_version}")

# Define Docker container for Apptainer usage
containerized: f"docker://niekwit/damid-seq:{VERSION}"

# Load and validate config file
configfile: "config/config.yaml"
validate(config, "schemas/config.schema.yaml")

# Get paired-end status and bam extension
paired_end = paired_end()

# Get data type
if data_type() == "matrix":
    matrix_samples()

check_consensus_peak_settings()

plasmid_name = plasmid_fasta_name(config["plasmid_fasta"])

# Load sample information
csv = pd.read_csv("config/samples.csv")

# Load genome resources to be used in rules
resources = Resources(config["genome"], config["ensembl_genome_build"])

# Get fusion protein (to be masked in fasta file)
maskedgenes = masked_genes()

# Wildcard values
DIRS = dirs()
SAMPLES = samples() # Includes Dam control
BG_SAMPLES = samples(bedgraph=True) # SAMPLES minus Dam control
DAM_SAMPLES = samples(bedgraph=True, dam=True)
DBS = config["consensus_peaks"]["enrichment_analysis"]["dbs"]

# Import rules
include: "rules/fastqc.smk"
include: "rules/trimming.smk"
include: "rules/resources.smk"
include: "rules/damid.smk"
include: "rules/bedgraph_processing.smk"
include: "rules/deeptools.smk"
include: "rules/plotting.smk"
include: "rules/peak_calling_perl.smk"
include: "rules/macs2.smk"

localrules: all, get_fasta, get_gtf, install_damidseq_pipeline_software, install_find_peak_software, chrom_sizes

# Target rule
rule all:
    input: 
        targets()

# Save snakemake terminal output to log file
time = datetime.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
snake_log = f"logs/snakemake/{time}_snakemake.log"
os.makedirs("logs/snakemake", exist_ok=True)

onsuccess: 
    shell("cp -v {log} {snake_log}")
    logger.info("Analysis finished successfully!")
onerror:
    shell("cp -v {log} {snake_log}")
    logger.info(f"Analysis failed...\nCheck {snake_log} for details")
